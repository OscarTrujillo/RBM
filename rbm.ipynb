{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rbm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpzqamuXb2kI"
      },
      "source": [
        "#RBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkHvX6adMPU0"
      },
      "source": [
        "!pip install qiskit ipywidgets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwqYNrIlL_80"
      },
      "source": [
        "from qiskit import *\n",
        "from numpy import pi\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "#Tensorflow library. Used to implement machine learning models\n",
        "import tensorflow as tf\n",
        "#Dataframe manipulation library\n",
        "import pandas as pd\n",
        "#Graph plotting library\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH52odMskO1c"
      },
      "source": [
        "Generic class for qiskit circuit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P93GdzBLgQq2"
      },
      "source": [
        "class qCirc():\n",
        "  def __init__(self, _circ, _nqbits, _print = False):\n",
        "    self.__nqbits = _nqbits\n",
        "    self.__circ = _circ\n",
        "    if (_print ):\n",
        "      print(_circ)\n",
        "\n",
        "  def measure(self):\n",
        "    for ind in range (0, self.__nqbits):\n",
        "      self.__circ.measure(ind, ind)\n",
        "\n",
        "  def get_datasource(self, nshots):\n",
        "    backend_sim = Aer.get_backend('qasm_simulator')\n",
        "    self.measure()\n",
        "    job_sim = execute(self.__circ, backend_sim, shots = nshots, memory=True)\n",
        "    result_sim = job_sim.result()\n",
        "    data =  result_sim.get_memory()\n",
        "  \n",
        "    #counts = result_sim.get_counts(self.__circuit)\n",
        "    #print(counts)\n",
        "    list_ = []\n",
        "    for num in data:\n",
        "      list_.append([int(numeric_string) for numeric_string in list(num)])\n",
        "    return  tf.convert_to_tensor(list_,tf.float32)\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u5zS2GzCso1"
      },
      "source": [
        "#W State with 'n' qubits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnZxVABOCZiR"
      },
      "source": [
        "class qWn(qCirc):\n",
        "  # Define a F_gate\n",
        "  def __F_gate(self,circ,q,i,j,n,k) :\n",
        "    theta = np.arccos(np.sqrt(1/(n-k+1)))\n",
        "    circ.ry(-theta,q[j])       \n",
        "    circ.cz(q[i],q[j])\n",
        "    circ.ry(theta,q[j])\n",
        "    circ.barrier(q[i])\n",
        "  def __init__(self, nqbits = 5, _print = False):\n",
        "    qreg_q = QuantumRegister(nqbits, 'q')\n",
        "    creg_c = ClassicalRegister(nqbits, 'c')\n",
        "    circ = QuantumCircuit(qreg_q, creg_c)\n",
        "    circ.x(qreg_q[nqbits-1]) #start is |10000>\n",
        "    for i in range(nqbits):\n",
        "      if (i+1 < nqbits):\n",
        "        self.__F_gate(circ, qreg_q, nqbits-1-i, nqbits-2-i, nqbits, i+1)\n",
        "    for i in range(nqbits):\n",
        "      if (i+1 < nqbits):\n",
        "        circ.cx(qreg_q[nqbits-2-i],qreg_q[nqbits-1-i])\n",
        "    super().__init__(circ, nqbits, _print)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY27_wLDKjD9",
        "outputId": "603a0664-4800-415a-97d8-774a4d4b000d"
      },
      "source": [
        "# Test qW20 with qWn\n",
        "qw20 = qWn(20, False)\n",
        "data_qw20 = qw20.get_datasource(10)\n",
        "print( data_qw20)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]], shape=(10, 20), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C02pjEdJWBWr"
      },
      "source": [
        "## RBM Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJaOp0wfVm5F"
      },
      "source": [
        "import random\n",
        "class RBM:\n",
        "  def __init__(self, visualUnits, hiddenUnits, alpha = 0.1 ):\n",
        "    self.epoch_div = 10\n",
        "    self.__hiddenUnits = hiddenUnits\n",
        "    self.__visualUnits = visualUnits\n",
        "    self.__alpha = alpha\n",
        "    self.__reset_params()\n",
        "\n",
        "  def __reset_params(self):\n",
        "    self.__vb = tf.Variable(tf.zeros([self.__visualUnits]), tf.float32)              # Visual Layer bias\n",
        "    self.__hb = tf.Variable(tf.zeros([self.__hiddenUnits]), tf.float32)               # Hidden Layer bias\n",
        "    self.__W  = tf.Variable(tf.zeros([self.__visualUnits, self.__hiddenUnits]), tf.float32) # Weight matrix\n",
        "  \n",
        "  def get_vb( self ):\n",
        "    return self.__vb\n",
        "  def put_vb(self, vb):\n",
        "    self.__vb = vb\n",
        "  def get_hb( self ):\n",
        "    return self.__hb\n",
        "  def put_hb( self, hb):\n",
        "    self.__hb = hb\n",
        "  def get_W( self ):\n",
        "    return self.__W\n",
        "  def put_W(self, w):\n",
        "    self.__W = w\n",
        "\n",
        "  def get_sigma_tests( self, n , ntrips = 10):\n",
        "    list = []\n",
        "    qbits_number = self.__visualUnits\n",
        "  \n",
        "    for index in range(n):\n",
        "      random_list = [random.randint(0, 1) for _ in range(qbits_number)]\n",
        "      visual_0 = tf.convert_to_tensor(random_list,tf.float32)\n",
        "\n",
        "      for ii in range (ntrips):   \n",
        "        hidden_0 = self.make_hidden_layer(visual_0)\n",
        "        visual_1 = self.remake_visual_layer(hidden_0)\n",
        "        visual_0 = visual_1\n",
        "      \n",
        "      list.append(visual_1.numpy().tolist())\n",
        "    \n",
        "    return list\n",
        "\n",
        "  def make_hidden_layer(self, visual_state):\n",
        "    hidden_proba = tf.nn.sigmoid(tf.matmul([visual_state], self.__W) + self.__hb)  # probabilities of the hidden units\n",
        "    hidden_state = tf.nn.relu(tf.sign(hidden_proba - tf.random.uniform(tf.shape(hidden_proba)))) # sample_h_given_X\n",
        "    return hidden_state[0]\n",
        "\n",
        "  def remake_visual_layer(self, hidden_state_source ):\n",
        "    visual_proba = tf.nn.sigmoid(tf.matmul([hidden_state_source], tf.transpose(self.__W)) + self.__vb) \n",
        "    visual_state = tf.nn.relu(tf.sign(visual_proba - tf.random.uniform(tf.shape(visual_proba)))) #sample_v_given_h\n",
        "    return visual_state[0]\n",
        "   \n",
        "  def error(self,v0_state, v1_state):\n",
        "    return tf.reduce_mean(tf.square(v0_state - v1_state))\n",
        "\n",
        "  def train(self, data_set, epochs = 100, every_epochs = 50, show = False):\n",
        "    every_epochs = epochs / self.epoch_div\n",
        "    self.__reset_params()\n",
        "    by_epochs = []\n",
        "    ind_epoch  = 0\n",
        "    step = 0\n",
        "    for epoch in range(1, epochs + 1):\n",
        "      ind_epoch += 1\n",
        "      for item in data_set: # cada item es del tipo [1.,0.,0.]\n",
        "        visual_0 = item\n",
        "        hidden_0 = self.make_hidden_layer(visual_0)\n",
        "        visual_1 = self.remake_visual_layer(hidden_0)\n",
        "        hidden_1 = self.make_hidden_layer(visual_1)\n",
        "        delta_W = tf.matmul(tf.transpose([visual_0]), [hidden_0]) - tf.matmul(tf.transpose([visual_1]), [hidden_1])\n",
        "        # los valores de los elementos de delta_w pueden ser sÃ³lo -1, 0 , 1\n",
        "        self.__W = self.__W + self.__alpha * delta_W\n",
        "        self.__vb = self.__vb + self.__alpha * tf.reduce_mean(visual_0 - visual_1, 0)\n",
        "        self.__hb = self.__hb + self.__alpha * tf.reduce_mean(hidden_0 - hidden_1, 0) \n",
        "        step += 1\n",
        "      if (ind_epoch >= every_epochs):\n",
        "        ind_epoch = 0\n",
        "        data = [epoch, step, self.__vb, self.__hb,self.__W]\n",
        "        by_epochs.append(data)\n",
        "        if show:\n",
        "          print (\"   >> training >> epoch = \" + str(epoch))\n",
        "    return by_epochs\n",
        "\n",
        "  def check(self,data):\n",
        "    nerr = 0\n",
        "    count_err = 0\n",
        "    for item in data:\n",
        "      check_visual_0 = item\n",
        "      check_hidden_0 = self.make_hidden_layer(check_visual_0)\n",
        "      check_visual_1 = self.remake_visual_layer(check_hidden_0)\n",
        "      err = tf.reduce_mean(tf.abs(check_visual_1 - check_visual_0), 0) \n",
        "      nerr = nerr + err\n",
        "      if (err != 0):\n",
        "        count_err += 1\n",
        "        print(check_visual_0)\n",
        "        print(check_visual_1)\n",
        "        print('-------------------')\n",
        "    nerr = nerr / len(data) \n",
        "    tf.print(nerr)\n",
        "    print (str(count_err) + \" errors of \" + str(len(data)))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3uP5keTPONh"
      },
      "source": [
        "#Overlap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoTSG2xDahov"
      },
      "source": [
        "class Overlap:\n",
        "\n",
        "  def _sumList(self, numList):\n",
        "    result = 0\n",
        "    for i in numList:\n",
        "      result += i\n",
        "    return result\n",
        "    \n",
        "  def _calculate_probability_distribution(self, sigmas, vb, hb, w):\n",
        "    e = math.e\n",
        "    n_visual_layer = len(vb)\n",
        "    n_hidden_layer = len(hb)\n",
        "    probabilities = [] #P_k(sigma)\n",
        "    for sigma in sigmas: \n",
        "      sum_bsig = 0\n",
        "      for v in range(n_visual_layer):\n",
        "        sum_bsig += vb[v] * sigma[v]\n",
        "\n",
        "      sum_log = 0\n",
        "      for i in range(n_hidden_layer): \n",
        "        sum_wij = 0\n",
        "        for j in range(n_visual_layer):\n",
        "          sum_wij += w[j][i] * sigma[j]\n",
        "        sum_log += math.log(1 + pow(e, hb[i] + sum_wij))\n",
        "\n",
        "      probabilities.append(pow(e, sum_bsig + sum_log))\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "\n",
        "  # calculate overlap between `state wave function`(psi_w) and the `RBM wave function`\n",
        "  def _calculate_overlap(self, sigmas_ok, sigmas_all, b, c, w, psi_w, print_prob = False):\n",
        "    probability_distributions_ok = self._calculate_probability_distribution(sigmas_ok, b, c, w) #P_lambda(sigma)\n",
        "    probability_distributions_all = self._calculate_probability_distribution(sigmas_all, b, c, w) #P_lambda(sigma)\n",
        "\n",
        "    Z = self._sumList(probability_distributions_all) #Z\n",
        "    if (print_prob):\n",
        "      tf.print(\"> Overlap Class > Probability Distribution = \" , probability_distributions_ok)\n",
        "      tf.print(\"> Overlap Class > sum Z = \", Z)\n",
        "      probnor = probability_distributions_ok / Z\n",
        "      tf.print(\"> Overlap Class > Probability Distr. norm. = \" , probnor)\n",
        "    psi_lambda_results = []\n",
        "    mult_results = []\n",
        "    for p in probability_distributions_ok:\n",
        "        psi_lamda = math.sqrt(p/Z) #RBM wave-function\n",
        "        #mult_results.append(psi_w * psi_lamda)\n",
        "        mult_results.append(psi_w * psi_lamda)\n",
        "    o = self._sumList(mult_results)\n",
        "    return o\n",
        "\n",
        "  def _intersection(self, lst1, lst2):\n",
        "    lst3 = [value for value in lst1 if value in lst2]\n",
        "    return lst3\n",
        "\n",
        "  def _estimate_overlap(self, sigmas_ok, sigmas_test, b, c, w):\n",
        "    probability_distributions = self._calculate_probability_distribution(sigmas_ok, b, c, w) #P_lambda(sigma)\n",
        "    sigmas_intersection = self._intersection(sigmas_test, sigmas_ok)\n",
        "    probability_distributions_intersection = self._calculate_probability_distribution(sigmas_intersection, b, c, w)\n",
        "    sum1 = 0\n",
        "    sum3 = 0\n",
        "    N = len(sigmas_ok)\n",
        "    n = len(sigmas_test)\n",
        "    n_intersection = len(sigmas_intersection)\n",
        "\n",
        "    print('n', n, 'N', N, 'sigmas_intersection', len(sigmas_intersection))\n",
        "    k = 1/math.sqrt(N)\n",
        "  \n",
        "    for pj in probability_distributions_intersection:\n",
        "      sum1 = sum1 + ((1/math.sqrt(pj))*k)\n",
        "    #1/âN   correcto??\n",
        "    for pk in probability_distributions:\n",
        "      sum3 = sum3 + math.sqrt(pk/N)\n",
        "    tf.print(\"sum1 = \", sum1)\n",
        "    tf.print(\"sum3 = \", sum3)\n",
        "    return ((1/n)*sum1)*sum3  \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDAcP3rBNYhA"
      },
      "source": [
        "class Overlap_Wn(Overlap):\n",
        "  def __init__(self, rbm: RBM, generateAllSigmas = False):\n",
        "    self.__rbm = rbm\n",
        "    self.__vb = rbm.get_vb()\n",
        "    self.__hb = rbm.get_hb()\n",
        "    self.__w = rbm.get_W()\n",
        "    self.__sigmas_ok = self._get_sigmas_ok(self.__vb)\n",
        "    if generateAllSigmas:\n",
        "      self.__sigmas_all = self._get_sigmas_all( self.__vb )\n",
        "    self.__psi_w = 1/math.sqrt(len(self.__sigmas_ok)) #w-state wave-function  nÃºmero de qubits\n",
        "\n",
        "  def get_overlap(self, print_prob_distribution = False, b = 0, c = 0, w = 0 ):\n",
        "    if len(b) == 0:\n",
        "      b = self.__vb\n",
        "    if len(c) == 0:\n",
        "      c = self.__hb\n",
        "    if len(w) == 0:\n",
        "      w = self.__w\n",
        "    return self._calculate_overlap(sigmas_ok = self.__sigmas_ok, sigmas_all = self.__sigmas_all, b = b, c = b, w = w, psi_w = self.__psi_w, print_prob =  print_prob_distribution)\n",
        "  \n",
        "  def estimate_overlap(self, sigmas_test, b = 0, c = 0, w = 0):\n",
        "    if len(b) == 0:\n",
        "      b = self.__vb\n",
        "    if len(c) == 0:\n",
        "      c = self.__hb\n",
        "    if len(w) == 0:\n",
        "      w = self.__w\n",
        "    return self._estimate_overlap(sigmas_ok = self.__sigmas_ok, sigmas_test = sigmas_test, b = b, c = c, w = w)\n",
        "   \n",
        "  def _get_sigmas_all(self, size):\n",
        "    initial_array = [0] * size\n",
        "    final_list = self._generate_list(initial_array, [])\n",
        "    return final_list\n",
        "\n",
        "  def _get_sigmas_ok(self, size):\n",
        "    final_list = []\n",
        "    for i in range(size):\n",
        "        array = [0] * size\n",
        "        array[i] = 1\n",
        "        final_list.append(array)\n",
        "    return final_list\n",
        "\n",
        "  def _sumList(self, numList):\n",
        "    result = 0\n",
        "    for i in numList:\n",
        "      result += i\n",
        "    return result\n",
        "\n",
        "  def _sum_1(self, array):\n",
        "    reversed_array = array[::-1]\n",
        "    for i, num in list(enumerate(reversed_array)):\n",
        "      if num == 0:\n",
        "        reversed_array[i] = 1\n",
        "        break\n",
        "      else:\n",
        "        reversed_array[i] = 0\n",
        "    return reversed_array[::-1]\n",
        "  def _generate_list(self, array, final_list):\n",
        "    final_list.append(array)\n",
        "    array = self._sum_1(array)\n",
        "    if np.any(array):\n",
        "      self._generate_list(array, final_list)\n",
        "    return final_list\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClYPaPu_o-GV"
      },
      "source": [
        "## Persist class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "5vawbLKOZ1rH",
        "outputId": "d53ab9d5-b325-4690-a3de-e84b7f1d8911"
      },
      "source": [
        "import json\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "class Persist:\n",
        "  def __init__(self, v, h, alpha, nset, epochs_total, epochs_div = 10):\n",
        "    self.__v = v\n",
        "    self.__h = h\n",
        "    self.__alpha = alpha\n",
        "    self.__nset = nset\n",
        "    self.__epochs_div = epochs_div\n",
        "    self.__epochs_total = epochs_total\n",
        "    self.__dir = 'drive/MyDrive/rbm/'\n",
        "    self.__filenameRBM = str('{:02}'.format(v)) + \"v\" \\\n",
        "                    + str('{:02}'.format(h)) + \"h\" \\\n",
        "                    + str('{:02}'.format(int(alpha*100))) + \"a\" \\\n",
        "                    + str('{:05}'.format(nset)) + \"nset\" \\\n",
        "                    + str('{:03}'.format(epochs_total)) + \"tepo\" \n",
        "    print(\"filename_RBM = \", self.__filenameRBM)\n",
        "    self.__filename = 'acum_data'\n",
        "    self.__filenameRBM = self.__dir + self.__filenameRBM\n",
        "    self.__filename = self.__dir + self.__filename \n",
        "  def append(self, step, overlap):\n",
        "    file = open(self.__filename, \"a\", encoding=\"utf-8\")\n",
        "    data = [self.__v, self.__h, self.__alpha, self.__nset, self.__epochs_total, step, overlap]\n",
        "    js = json.dumps(data)\n",
        "    print(js, file = file)\n",
        "    file.close()\n",
        "  def read(self):\n",
        "    file = open(self.__filename, \"r\", encoding=\"utf-8\")\n",
        "    lines = file.readlines()\n",
        "    file.close()\n",
        "    all_data = []\n",
        "      \n",
        "    for line in lines:\n",
        "      if len(line) > 0:\n",
        "        data = json.loads (line)\n",
        "        if (data[0] == self.__v and\n",
        "            data[1] == self.__h and \n",
        "            data[2] == self.__alpha and \n",
        "            data[3] == self.__nset  and\n",
        "            data[4] == self.__epochs_total ) :\n",
        "          all_data.append(data)\n",
        "\n",
        "    return all_data\n",
        "\n",
        "  def write_RBM(self, step, vb, hb, w):\n",
        "    filenameRBM = self.__filenameRBM + str('{:05}'.format(step))\n",
        "    file = open(filenameRBM, \"w\", encoding=\"utf-8\")\n",
        "    data = [self.__v, self.__h, self.__alpha, self.__nset, self.__epochs_total, step, vb, hb, w]\n",
        "    js = json.dumps(data)\n",
        "    file.write(js)\n",
        "    file.close()\n",
        "  def trunc(self):\n",
        "    open(self.__filename, 'w').close()\n",
        "  def trunc_RBM(self):\n",
        "    open(self.__filenameRBM, 'w').close()\n",
        "  def read_RBM(self, step):\n",
        "    filenameRBM = self.__filenameRBM + str('{:05}'.format(step))\n",
        "    file = open(filenameRBM, \"r\", encoding=\"utf-8\")\n",
        "    js = file.read()\n",
        "    file.close()\n",
        "    print('js=' , js)\n",
        "    data = json.loads(js)\n",
        "    rbm = RBM(visualUnits = data[0], hiddenUnits = data[1], alpha = data[2])\n",
        "    rbm.put_vb(vb = data[6])\n",
        "    rbm.put_hb(hb = data[7])\n",
        "    rbm.put_W(w  = data[8])\n",
        "    return rbm\n",
        "'''    \n",
        "persist = Persist( v = 5, h = 5, alpha = 0.4, nset = 200, epochs = 20 )\n",
        "persist.append(30)\n",
        "print(persist.read())\n",
        "#persist.trunc()\n",
        "'''\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'    \\npersist = Persist( v = 5, h = 5, alpha = 0.4, nset = 200, epochs = 20 )\\npersist.append(30)\\nprint(persist.read())\\n#persist.trunc()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "speUXSC3pF_F"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzr4E0AUN6YY"
      },
      "source": [
        "class TestWn:\n",
        "  def __init__(self,n_visuallayer = 5, n_hiddenlayer = 5, alpha = 0.5, n_epochs = 10, n_data_source = 200 ):\n",
        "    self.__rbm = RBM(n_visuallayer, n_hiddenlayer ,alpha = alpha )\n",
        "    qwn = qWn(n_visuallayer, False)\n",
        "    self.__data = qwn.get_datasource(n_data_source)\n",
        "    self.__max_epoch = n_epochs\n",
        "  def train(self):\n",
        "    print(\"training rbm with epochs = \", self.__max_epoch)\n",
        "    by_epoch = self.__rbm.train( data_set = self.__data, epochs = self.__max_epoch)\n",
        "    print(\"rbm trained \")\n",
        "    return by_epoch\n",
        "\n",
        "  def get_overlap(self, b, c, w):\n",
        "    Ovl = Overlap_Wn( self.__rbm)\n",
        "    \n",
        "    return Ovl.get_overlap( print_prob_distribution = True, b = b, c = c, w = w )\n",
        "\n",
        "  def cal_overlap(self, b,c,w, n = 1000):\n",
        "    Ovl = Overlap_Wn( self.__rbm )\n",
        "    return Ovl.cal_overlap( sigmas_test = self.__rbm.get_sigma_tests(n) , b = b, c = c, w = w )\n",
        "\n",
        "  def gibb( self, n = 100):\n",
        "    return self.__rbm.get_sigma_tests( n )\n",
        "  \n",
        "  def good_gibb( self, n = 100 ):\n",
        "   return self._filter_sigmas( self.gibb( n ))\n",
        "\n",
        "  def _filter_sigmas( self, sigmas_tests):\n",
        "    good_sigmas = []\n",
        "    for s in sigmas_tests:\n",
        "      if sum(s) == 1:\n",
        "        good_sigmas.append(s.index(1) + 1)\n",
        "    return good_sigmas\n",
        "\n",
        "  def saveRBM(self):\n",
        "    persist = Persist( v = self.__rbm.get_v)\n",
        "    def __init__(self, v, h, alpha, nset, epochs_total, epochs_div = 10):\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa5KXGoyL9hk"
      },
      "source": [
        "#train one RBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8IkdPdwMBxl"
      },
      "source": [
        "alpha = 0.5\n",
        "n_epochs = 10\n",
        "testN200 = TestWn( 20, 20, alpha = alpha, n_epochs = n_epochs , n_data_source = 200 )\n",
        "testN200.train()\n",
        "\n",
        "testN500 = TestWn( 20, 20, alpha = alpha, n_epochs = n_epochs , n_data_source = 500 )\n",
        "testN500.train()\n",
        "testN1000 = TestWn( 20, 20, alpha = alpha, n_epochs = n_epochs , n_data_source = 1000 )\n",
        "testN1000.train()\n",
        "testN2000 = TestWn( 20, 20, alpha = alpha, n_epochs = n_epochs , n_data_source = 2000 )\n",
        "testN2000.train()\n",
        "testN20000 = TestWn( 20, 20, alpha = alpha, n_epochs = n_epochs , n_data_source = 20000 )\n",
        "testN20000.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfET66Pic58O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFJxMmemRi9H"
      },
      "source": [
        "class Plot:\n",
        "  def __init__(self, sigmas):\n",
        "    self.__sigmas = sigmas\n",
        "  def show(self):\n",
        "    length = len(self.__sigmas)\n",
        "    unique, rev = np.unique(self.__sigmas, return_inverse=True)\n",
        "    np.bincount(rev)\n",
        "    X = np.column_stack((unique,np.bincount(rev)/length))\n",
        "\n",
        "    plt.bar(x=X[:, 0], height=X[:, 1])\n",
        "    plt.xticks(unique)\n",
        "    plt.yticks(np.arange(0, 0.2, step=0.02))\n",
        "    plt.show()    \n",
        "\n",
        "plotN200 = Plot( testN200.good_gibb(1000) )\n",
        "plotN200.show()\n",
        "\n",
        "plotN500 = Plot( testN500.good_gibb(1000) )\n",
        "plotN500.show()\n",
        "\n",
        "plotN1000 = Plot( testN1000.good_gibb(1000) )\n",
        "plotN1000.show()\n",
        "\n",
        "plotN2000 = Plot( testN2000.good_gibb(1000) )\n",
        "plotN2000.show()\n",
        "\n",
        "plotN20000 = Plot( testN2000.good_gibb(1000) )\n",
        "plotN20000.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "5vma1bZbc-jG",
        "outputId": "31cd30e1-6592-4942-de2d-92f5ce594747"
      },
      "source": [
        "test = TestWn( 20, 20, alpha = 0.1, n_epochs = 10 , n_data_source = 20000 )\n",
        "test.train()\n",
        "plot = Plot(test.good_gibb(1000))\n",
        "plot.show()\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training rbm with epochs =  10\n",
            "rbm trained \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7L9JLNd70_4"
      },
      "source": [
        "#multi train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfoL3kyi7zFm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "outputId": "b70f1b98-6887-4801-88e3-f67af4e3a19c"
      },
      "source": [
        "# \n",
        "n_visual = 7\n",
        "n_hidden = 5\n",
        "array_alpha = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "array_n_data_set = [50,100,200,500,1000]\n",
        "array_n_data_set = [100]\n",
        "n_epochs_max = 100\n",
        "do_persist = False\n",
        "\n",
        "for n_data_set in array_n_data_set:\n",
        "  for alpha in array_alpha:\n",
        "    if do_persist:\n",
        "      persist = Persist(v = n_visual , h = n_hidden, alpha = alpha, nset = n_data_set , epochs_total = n_epochs_max ) \n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    test = TestWn( n_visuallayer = n_visual, n_hiddenlayer = n_hidden, alpha = alpha, n_epochs = n_epochs_max, n_data_source = n_data_set )\n",
        "    by_epoch = test.train()\n",
        "    min = 1\n",
        "    for epo in by_epoch:\n",
        "    #data = [epoch, step, self.__vb, self.__hb,self.__W]\n",
        "      epoch_num = epo[0]\n",
        "      step = epo[1]\n",
        "      vb = epo[2]\n",
        "      hb = epo[3]\n",
        "      w  = epo[4]\n",
        "      epoch_num_str = str(epoch_num)\n",
        "      vb_str = vb.numpy().tolist()\n",
        "      hb_str = hb.numpy().tolist()\n",
        "      w_str  = w.numpy().tolist()\n",
        "\n",
        "      print('calculating overlap of epoch = ' + epoch_num_str)\n",
        "      over_value = test.get_overlap( b = vb, c = hb, w = w)\n",
        "      print(\"overlap = \", over_value)\n",
        "      if do_persist:\n",
        "        persist.append(step = step, overlap = over_value)\n",
        "        persist.write_RBM(step = step, vb = vb_str, hb = hb_str, w = w_str )\n",
        "      \n",
        "      x.append(epo[0])\n",
        "      y.append(over_value)\n",
        "      if (over_value < min) :\n",
        "        min = over_value\n",
        "\n",
        "  if (min > 0.8):\n",
        "    min = 0.8\n",
        "  plt.ylim(min,1)\n",
        "  xi = list(range(len(x)))\n",
        "  plt.xticks(xi, x)\n",
        "  plt.plot(x,y,marker='o')\n",
        "  plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training rbm with epochs =  100\n",
            "   >> training >> epoch = 10\n",
            "   >> training >> epoch = 20\n",
            "   >> training >> epoch = 30\n",
            "   >> training >> epoch = 40\n",
            "   >> training >> epoch = 50\n",
            "   >> training >> epoch = 60\n",
            "   >> training >> epoch = 70\n",
            "   >> training >> epoch = 80\n",
            "   >> training >> epoch = 90\n",
            "   >> training >> epoch = 100\n",
            "rbm trained \n",
            "calculating overlap of epoch = 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-686bc7607070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'calculating overlap of epoch = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepoch_num_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m       \u001b[0mover_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_overlap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overlap = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mover_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdo_persist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-b9ecdb49eafd>\u001b[0m in \u001b[0;36mget_overlap\u001b[0;34m(self, b, c, w)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mOvl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOverlap_Wn\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__rbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__nvisual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mOvl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_overlap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-14349eae9346>\u001b[0m in \u001b[0;36mget_overlap\u001b[0;34m(self, print_prob_distribution, b, c, w)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_overlap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmas_ok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sigmas_ok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmas_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sigmas_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__psi_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_prob\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mprint_prob_distribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_intersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Overlap_Wn' object has no attribute '_Overlap_Wn__sigmas_all'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86c89H5v2zo9"
      },
      "source": [
        "#multi read (different alphas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHCZnxpA9_Od"
      },
      "source": [
        " read_nvis = 5\n",
        " read_hidden = 5\n",
        " read_n_data_set = 5000\n",
        " read_n_epochs = 10\n",
        " \n",
        " x = []\n",
        " y = []\n",
        " min = 1\n",
        " max = 0\n",
        "\n",
        " read_alpha_array = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        " count = 0\n",
        " for read_alpha in read_alpha_array:\n",
        "   y.append([])\n",
        "\n",
        "   read_persist = Persist(v = read_nvis , h = read_hidden, alpha = read_alpha, nset = read_n_data_set , epochs_total = read_n_epochs   )\n",
        "   read_data = read_persist.read()\n",
        "\n",
        "   for data in read_data:\n",
        "     print (data)\n",
        "     if (count == 0):\n",
        "       x.append(data[5])  \n",
        "     y[count].append(data[6])\n",
        "     if data[6] > max:\n",
        "       max = data[6]\n",
        "     if (min > data[6]) :\n",
        "       min = data[6]\n",
        "   count += 1\n",
        "\n",
        "\n",
        " if (min > 0.8):\n",
        "   min = 0.8\n",
        " plt.ylim(min,1)\n",
        " greek_letterz=[chr(code) for code in range(945,970)]\n",
        " plt.plot(x,y[0], marker='o', label = greek_letterz[0] + ' = 0.1', color=(0,0,0 ))\n",
        " plt.plot(x,y[1], marker='o', label = greek_letterz[0] + ' = 0.3', color=(0,0,1 ), linestyle='--')\n",
        " plt.plot(x,y[2], marker='o', label = greek_letterz[0] + ' = 0.5', color=(1,0,0 ))\n",
        " plt.plot(x,y[3], marker='o', label = greek_letterz[0] + ' = 0.7', color=(0,1,1 ),linestyle='--')\n",
        " plt.plot(x,y[4], marker='o', label = greek_letterz[0] + ' = 0.9', color=( 0.8,0.8,0.8))\n",
        " plt.legend(loc='lower right')\n",
        " plt.title('N = ' + str(read_n_data_set )  + ' hidden = ' + str(read_hidden) + ' epochs =' + str(read_n_epochs) + ' Max =' + str('{:.4f}'.format(max)) )\n",
        "\n",
        " plt.show()  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCxpPs_FVJSc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQjQ5M-S5j-A"
      },
      "source": [
        "# find maximum overlap\n",
        "\n",
        "def mySort(data):\n",
        "  return data[6]\n",
        "\n",
        "file = open( 'drive/MyDrive/rbm/acum_data', \"r\", encoding=\"utf-8\")\n",
        "  lines = file.readlines()\n",
        "  file.close()\n",
        "  all_data = []\n",
        "      \n",
        "  for line in lines:\n",
        "    if len(line) > 0:\n",
        "      data = json.loads (line)\n",
        "      all_data.append(data)\n",
        "    \n",
        "  all_data.sort(key=mySort)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ9jdAcNQg-U"
      },
      "source": [
        "#gibb sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOYOdq8AvDX8"
      },
      "source": [
        "#Training without overlap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVFV-_TKuYpI",
        "outputId": "eca1eec4-8424-4c8b-c8fc-d80cefff6132"
      },
      "source": [
        "\n",
        "n_visual = 20\n",
        "n_hidden = 5\n",
        "array_alpha = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "array_alpha = [0.1]\n",
        "array_n_data_set = [100]\n",
        "n_epochs_max = 10\n",
        "\n",
        "for n_data_set in array_n_data_set:\n",
        "  for alpha in array_alpha:\n",
        "    persist = Persist(v = n_visual , h = n_hidden, alpha = alpha, nset = n_data_set , epochs_total = n_epochs_max ) \n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    test = TestWn(n_visuallayer = n_visual, n_hiddenlayer = n_hidden, alpha = alpha, n_epochs = n_epochs_max, n_data_source = n_data_set )\n",
        "    by_epoch = test.train()\n",
        "    min = 1\n",
        "    for epo in by_epoch:\n",
        "    #data = [epoch, step, self.__vb, self.__hb,self.__W]\n",
        "      epoch_num = epo[0]\n",
        "      step = epo[1]\n",
        "      vb = epo[2]\n",
        "      hb = epo[3]\n",
        "      w  = epo[4]\n",
        "      epoch_num_str = str(epoch_num)\n",
        "      vb_str = vb.numpy().tolist()\n",
        "      hb_str = hb.numpy().tolist()\n",
        "      w_str  = w.numpy().tolist()\n",
        "\n",
        "      persist.write_RBM(step = step, vb = vb_str, hb = hb_str, w = w_str )\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "filename_RBM =  20v05h10a00100nset010tepo\n",
            "training rbm with epochs =  10\n",
            "   >> training >> epoch = 1\n",
            "   >> training >> epoch = 2\n",
            "   >> training >> epoch = 3\n",
            "   >> training >> epoch = 4\n",
            "   >> training >> epoch = 5\n",
            "   >> training >> epoch = 6\n",
            "   >> training >> epoch = 7\n",
            "   >> training >> epoch = 8\n",
            "   >> training >> epoch = 9\n",
            "   >> training >> epoch = 10\n",
            "rbm trained \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vn8DiCgQgSj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "f7851c70-541e-4e66-a70a-065e1caa7c5f"
      },
      "source": [
        "over_buena10 = Overlap_Wn( rbm_w5_buena10 )\n",
        "\n",
        "overlap_buena10 = over_buena10.get_overlap( True )\n",
        "tf.print(\"Overlap = \", overlap_buena10)\n",
        "estimation_buena10 = over_buena10.get_estimate_overlap(nsigmas = 1000, ntrips = 10)\n",
        "tf.print(\"Estimation Overlap ^2 = \", estimation_buena10)\n",
        "tf.print(\"Estimation Overlap =\", math.sqrt(estimation_buena10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-431c35a2102b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mover_buena10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOverlap_W5\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrbm_w5_buena10\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moverlap_buena10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mover_buena10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_overlap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Overlap = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap_buena10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mestimation_buena10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mover_buena10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_estimate_overlap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnsigmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntrips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'rbm_w5_buena10' is not defined"
          ]
        }
      ]
    }
  ]
}